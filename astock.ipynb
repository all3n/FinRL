{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suburban-consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n",
      "EPISODE:1:   0%|                                       | 0/2431 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121550\n",
      "24350\n",
      "Stock Dimension: 50, State Space: 301\n",
      "turbulence_threshold: 2183.354543800645\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from stable_baselines3.common.vec_env import VecCheckNan\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "today = datetime.datetime.today()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ARGS.gpu\n",
    "\n",
    "processed_full = pd.read_csv(\"data/datasets/processed_sz50.csv\")\n",
    "start_date = '2009-01-01'\n",
    "end_date = '2019-01-01'\n",
    "trade_date = '2021-01-01'\n",
    "train = data_split(processed_full, start_date, end_date)\n",
    "trade = data_split(processed_full, end_date, trade_date)\n",
    "print(len(train))\n",
    "print(len(trade))\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "\n",
    "data_turbulence = processed_full[(processed_full.date< end_date) & (processed_full.date>=start_date)]\n",
    "insample_turbulence = data_turbulence.drop_duplicates(subset=['date'])\n",
    "turbulence_threshold = np.quantile(insample_turbulence.turbulence.values,1)\n",
    "print(\"turbulence_threshold:\", turbulence_threshold)\n",
    "\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "agent = DRLAgent(env = env_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(model_name):\n",
    "    if model_name == \"s2c\" or model_name == \"ddpg\":\n",
    "        model = agent.get_model(model_name)\n",
    "    elif model_name == \"ppo\":\n",
    "        PPO_PARAMS = {\n",
    "            \"n_steps\": 2048,\n",
    "            \"ent_coef\": 0.01,\n",
    "            \"learning_rate\": 0.00025,\n",
    "            \"batch_size\": 128,\n",
    "        }\n",
    "        model = agent.get_model(model_name, model_kwargs = PPO_PARAMS)\n",
    "    elif model_name == 'td3':\n",
    "        TD3_PARAMS = {\"batch_size\": 100,\n",
    "              \"buffer_size\": 1000000,\n",
    "              \"learning_rate\": 0.001}\n",
    "        model = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "    elif model_name == 'sac':\n",
    "        SAC_PARAMS = {\n",
    "            \"batch_size\": 128,\n",
    "            \"buffer_size\": 1000000,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"learning_starts\": 100,\n",
    "            \"ent_coef\": \"auto_0.1\",\n",
    "        }\n",
    "\n",
    "        model = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_path = \"./trained_models/\"\n",
    "def train(model_name, total_timesteps):\n",
    "    model = get_model(model_name)\n",
    "    trained = agent.train_model(model=model,\n",
    "                             tb_log_name=model_name,\n",
    "                             total_timesteps=total_timesteps)\n",
    "    trained.save(model_path + model_name)\n",
    "    return trained\n",
    "\n",
    "def load(model_name):\n",
    "    return agent.load_model(model_name,model_path+ model_name)\n",
    "\n",
    "\n",
    "def load_or_train(model_name, total_timesteps = 30000):\n",
    "    if os.path.exists(model_path + model_name + \".zip\"):\n",
    "        print(\"load \" + model_name)\n",
    "        return load(model_name)\n",
    "    else:\n",
    "        return train(model_name, total_timesteps)\n",
    "\n",
    "#train(\"a2c\", 100000)\n",
    "#train(\"ddpg\", 50000)\n",
    "#train(\"ppo\", 50000)\n",
    "#train(\"td3\", 30000)\n",
    "#train(\"sac\", 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statewide-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ddpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EPISODE:1:   0%|                                        | 0/487 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "EPISODE:2:   0%|                                        | 0/487 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stable_baselines3.ddpg.ddpg.DDPG object at 0x7f674754b588>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPISODE:2:   0%|                                | 1/487 [00:00<01:46,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:1:   0%|                                        | 0/487 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "EPISODE:2:  15%|████▋                          | 74/487 [00:00<00:44,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  23%|██████▉                       | 112/487 [00:00<00:28, 13.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  31%|█████████▏                    | 149/487 [00:00<00:18, 18.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  38%|███████████▍                  | 186/487 [00:00<00:11, 25.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  46%|█████████████▋                | 223/487 [00:00<00:07, 35.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  53%|████████████████              | 260/487 [00:00<00:04, 48.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  61%|██████████████████▎           | 297/487 [00:01<00:02, 65.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  69%|████████████████████▌         | 334/487 [00:01<00:01, 87.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  76%|██████████████████████       | 371/487 [00:01<00:01, 113.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  84%|████████████████████████▎    | 408/487 [00:01<00:00, 142.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2:  91%|██████████████████████████▍  | 445/487 [00:01<00:00, 174.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:2: 100%|█████████████████████████████| 487/487 [00:01<00:00, 310.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "EPISODE:3:   0%|                                        | 0/487 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "           date  account_value\n",
      "0    2019-01-02   1.000000e+06\n",
      "1    2019-01-03   9.988078e+05\n",
      "2    2019-01-04   1.003929e+06\n",
      "3    2019-01-07   1.004908e+06\n",
      "4    2019-01-08   1.003308e+06\n",
      "..          ...            ...\n",
      "482  2020-12-25   2.612790e+06\n",
      "483  2020-12-28   2.649823e+06\n",
      "484  2020-12-29   2.661679e+06\n",
      "485  2020-12-30   2.739417e+06\n",
      "486  2020-12-31   2.813198e+06\n",
      "\n",
      "[487 rows x 2 columns]\n",
      "            sh.600000  sh.600009  sh.600016  sh.600028  sh.600030  sh.600031  \\\n",
      "date                                                                           \n",
      "2019-01-02        100          0          0          0          0        100   \n",
      "2019-01-03        100          0          0          0          0        100   \n",
      "2019-01-04        100          0          0          0          0        100   \n",
      "2019-01-07        100          0          0          0          0        100   \n",
      "2019-01-08        100          0          0          0          0        100   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2020-12-24          0          0          0          0          0          0   \n",
      "2020-12-25          0          0          0          0          0          0   \n",
      "2020-12-28          0          0          0          0          0          0   \n",
      "2020-12-29          0          0          0          0          0          0   \n",
      "2020-12-30          0          0          0          0          0          0   \n",
      "\n",
      "            sh.600036  sh.600048  sh.600050  sh.600104  ...  sh.601688  \\\n",
      "date                                                    ...              \n",
      "2019-01-02          0          0          0          0  ...        100   \n",
      "2019-01-03          0          0          0          0  ...        100   \n",
      "2019-01-04          0          0          0          0  ...        100   \n",
      "2019-01-07          0          0          0          0  ...        100   \n",
      "2019-01-08          0          0          0          0  ...        100   \n",
      "...               ...        ...        ...        ...  ...        ...   \n",
      "2020-12-24          0          0          0          0  ...          0   \n",
      "2020-12-25          0          0          0          0  ...          0   \n",
      "2020-12-28          0          0          0          0  ...          0   \n",
      "2020-12-29          0          0          0          0  ...          0   \n",
      "2020-12-30          0          0          0          0  ...          0   \n",
      "\n",
      "            sh.601816  sh.601818  sh.601857  sh.601888  sh.603160  sh.603259  \\\n",
      "date                                                                           \n",
      "2019-01-02          0        100          0          0        100          0   \n",
      "2019-01-03          0        100          0          0        100          0   \n",
      "2019-01-04          0        100          0          0        100          0   \n",
      "2019-01-07          0        100          0          0        100          0   \n",
      "2019-01-08          0        100          0          0        100          0   \n",
      "...               ...        ...        ...        ...        ...        ...   \n",
      "2020-12-24          0          0          0          0          0          0   \n",
      "2020-12-25          0          0          0          0          0          0   \n",
      "2020-12-28          0          0          0          0          0          0   \n",
      "2020-12-29          0          0          0          0          0          0   \n",
      "2020-12-30          0          0          0          0          0          0   \n",
      "\n",
      "            sh.603288  sh.603501  sh.603986  \n",
      "date                                         \n",
      "2019-01-02          0          0        100  \n",
      "2019-01-03          0          0        100  \n",
      "2019-01-04          0          0        100  \n",
      "2019-01-07          0          0        100  \n",
      "2019-01-08          0          0        100  \n",
      "...               ...        ...        ...  \n",
      "2020-12-24          0          0          0  \n",
      "2020-12-25          0          0          0  \n",
      "2020-12-28          0          0          0  \n",
      "2020-12-29          0          0          0  \n",
      "2020-12-30          0          0          0  \n",
      "\n",
      "[486 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "#train(\"td3\", 10)\n",
    "#m = load_or_train(\"ddpg\", 10)\n",
    "#m = load_or_train(\"ppo\", 50000)\n",
    "#m = load_or_train(\"ddpg\", 50000)\n",
    "# m = load_or_train(\"sac\", 80000)\n",
    "m = load_or_train(\"ddpg\", 2)\n",
    "print(m)\n",
    "\n",
    "\n",
    "# simulate for trade\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = turbulence_threshold, **env_kwargs)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=m,\n",
    "    environment = e_trade_gym)\n",
    "\n",
    "print(df_account_value)\n",
    "print(df_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handmade-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.707813\n",
      "Cumulative returns     1.813198\n",
      "Annual volatility      0.273856\n",
      "Sharpe ratio           2.097305\n",
      "Calmar ratio           3.742701\n",
      "Stability              0.922184\n",
      "Max drawdown          -0.189118\n",
      "Omega ratio            1.434612\n",
      "Sortino ratio          3.232045\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.309267\n",
      "Daily value at risk   -0.032223\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-helena",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
